// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
import Foundation
import azureSwiftRuntime
internal struct DataLakeAnalyticsAccountPropertiesData : DataLakeAnalyticsAccountPropertiesProtocol, DataLakeAnalyticsAccountPropertiesBasicProtocol {
    public var accountId: String?
    public var provisioningState: DataLakeAnalyticsAccountStatusEnum?
    public var state: DataLakeAnalyticsAccountStateEnum?
    public var creationTime: Date?
    public var lastModifiedTime: Date?
    public var endpoint: String?
    public var defaultDataLakeStoreAccount: String?
    public var dataLakeStoreAccounts: [DataLakeStoreAccountInformationProtocol?]?
    public var storageAccounts: [StorageAccountInformationProtocol?]?
    public var computePolicies: [ComputePolicyProtocol?]?
    public var firewallRules: [FirewallRuleProtocol?]?
    public var firewallState: FirewallStateEnum?
    public var firewallAllowAzureIps: FirewallAllowAzureIpsStateEnum?
    public var newTier: TierTypeEnum?
    public var currentTier: TierTypeEnum?
    public var maxJobCount: Int32?
    public var systemMaxJobCount: Int32?
    public var maxDegreeOfParallelism: Int32?
    public var systemMaxDegreeOfParallelism: Int32?
    public var maxDegreeOfParallelismPerJob: Int32?
    public var minPriorityPerJob: Int32?
    public var queryStoreRetention: Int32?

        enum CodingKeys: String, CodingKey {case accountId = "accountId"
        case provisioningState = "provisioningState"
        case state = "state"
        case creationTime = "creationTime"
        case lastModifiedTime = "lastModifiedTime"
        case endpoint = "endpoint"
        case defaultDataLakeStoreAccount = "defaultDataLakeStoreAccount"
        case dataLakeStoreAccounts = "dataLakeStoreAccounts"
        case storageAccounts = "storageAccounts"
        case computePolicies = "computePolicies"
        case firewallRules = "firewallRules"
        case firewallState = "firewallState"
        case firewallAllowAzureIps = "firewallAllowAzureIps"
        case newTier = "newTier"
        case currentTier = "currentTier"
        case maxJobCount = "maxJobCount"
        case systemMaxJobCount = "systemMaxJobCount"
        case maxDegreeOfParallelism = "maxDegreeOfParallelism"
        case systemMaxDegreeOfParallelism = "systemMaxDegreeOfParallelism"
        case maxDegreeOfParallelismPerJob = "maxDegreeOfParallelismPerJob"
        case minPriorityPerJob = "minPriorityPerJob"
        case queryStoreRetention = "queryStoreRetention"
        }

  public init()  {
  }

  public init(from decoder: Decoder) throws {
    let container = try decoder.container(keyedBy: CodingKeys.self)
      if container.contains(.accountId) {
        self.accountId = try container.decode(String?.self, forKey: .accountId)
    }
    if container.contains(.provisioningState) {
        self.provisioningState = try container.decode(DataLakeAnalyticsAccountStatusEnum?.self, forKey: .provisioningState)
    }
    if container.contains(.state) {
        self.state = try container.decode(DataLakeAnalyticsAccountStateEnum?.self, forKey: .state)
    }
    if container.contains(.creationTime) {
        self.creationTime = DateConverter.fromString(dateStr: (try container.decode(String?.self, forKey: .creationTime)), format: .dateTime)
    }
    if container.contains(.lastModifiedTime) {
        self.lastModifiedTime = DateConverter.fromString(dateStr: (try container.decode(String?.self, forKey: .lastModifiedTime)), format: .dateTime)
    }
    if container.contains(.endpoint) {
        self.endpoint = try container.decode(String?.self, forKey: .endpoint)
    }
    if container.contains(.defaultDataLakeStoreAccount) {
        self.defaultDataLakeStoreAccount = try container.decode(String?.self, forKey: .defaultDataLakeStoreAccount)
    }
    if container.contains(.dataLakeStoreAccounts) {
        self.dataLakeStoreAccounts = try container.decode([DataLakeStoreAccountInformationData?]?.self, forKey: .dataLakeStoreAccounts)
    }
    if container.contains(.storageAccounts) {
        self.storageAccounts = try container.decode([StorageAccountInformationData?]?.self, forKey: .storageAccounts)
    }
    if container.contains(.computePolicies) {
        self.computePolicies = try container.decode([ComputePolicyData?]?.self, forKey: .computePolicies)
    }
    if container.contains(.firewallRules) {
        self.firewallRules = try container.decode([FirewallRuleData?]?.self, forKey: .firewallRules)
    }
    if container.contains(.firewallState) {
        self.firewallState = try container.decode(FirewallStateEnum?.self, forKey: .firewallState)
    }
    if container.contains(.firewallAllowAzureIps) {
        self.firewallAllowAzureIps = try container.decode(FirewallAllowAzureIpsStateEnum?.self, forKey: .firewallAllowAzureIps)
    }
    if container.contains(.newTier) {
        self.newTier = try container.decode(TierTypeEnum?.self, forKey: .newTier)
    }
    if container.contains(.currentTier) {
        self.currentTier = try container.decode(TierTypeEnum?.self, forKey: .currentTier)
    }
    if container.contains(.maxJobCount) {
        self.maxJobCount = try container.decode(Int32?.self, forKey: .maxJobCount)
    }
    if container.contains(.systemMaxJobCount) {
        self.systemMaxJobCount = try container.decode(Int32?.self, forKey: .systemMaxJobCount)
    }
    if container.contains(.maxDegreeOfParallelism) {
        self.maxDegreeOfParallelism = try container.decode(Int32?.self, forKey: .maxDegreeOfParallelism)
    }
    if container.contains(.systemMaxDegreeOfParallelism) {
        self.systemMaxDegreeOfParallelism = try container.decode(Int32?.self, forKey: .systemMaxDegreeOfParallelism)
    }
    if container.contains(.maxDegreeOfParallelismPerJob) {
        self.maxDegreeOfParallelismPerJob = try container.decode(Int32?.self, forKey: .maxDegreeOfParallelismPerJob)
    }
    if container.contains(.minPriorityPerJob) {
        self.minPriorityPerJob = try container.decode(Int32?.self, forKey: .minPriorityPerJob)
    }
    if container.contains(.queryStoreRetention) {
        self.queryStoreRetention = try container.decode(Int32?.self, forKey: .queryStoreRetention)
    }
    if var pageDecoder = decoder as? PageDecoder  {
      if pageDecoder.isPagedData,
        let nextLinkName = pageDecoder.nextLinkName {
          pageDecoder.nextLink = try UnknownCodingKey.decodeStringForKey(decoder: decoder, keyForDecode: nextLinkName)
      }
    }
  }

  public func encode(to encoder: Encoder) throws {
    var container = encoder.container(keyedBy: CodingKeys.self)
    if self.accountId != nil {try container.encode(self.accountId, forKey: .accountId)}
    if self.provisioningState != nil {try container.encode(self.provisioningState, forKey: .provisioningState)}
    if self.state != nil {try container.encode(self.state, forKey: .state)}
    if self.creationTime != nil {
        try container.encode(DateConverter.toString(date: self.creationTime!, format: .dateTime), forKey: .creationTime)
    }
    if self.lastModifiedTime != nil {
        try container.encode(DateConverter.toString(date: self.lastModifiedTime!, format: .dateTime), forKey: .lastModifiedTime)
    }
    if self.endpoint != nil {try container.encode(self.endpoint, forKey: .endpoint)}
    if self.defaultDataLakeStoreAccount != nil {try container.encode(self.defaultDataLakeStoreAccount, forKey: .defaultDataLakeStoreAccount)}
    if self.dataLakeStoreAccounts != nil {try container.encode(self.dataLakeStoreAccounts as! [DataLakeStoreAccountInformationData?]?, forKey: .dataLakeStoreAccounts)}
    if self.storageAccounts != nil {try container.encode(self.storageAccounts as! [StorageAccountInformationData?]?, forKey: .storageAccounts)}
    if self.computePolicies != nil {try container.encode(self.computePolicies as! [ComputePolicyData?]?, forKey: .computePolicies)}
    if self.firewallRules != nil {try container.encode(self.firewallRules as! [FirewallRuleData?]?, forKey: .firewallRules)}
    if self.firewallState != nil {try container.encode(self.firewallState, forKey: .firewallState)}
    if self.firewallAllowAzureIps != nil {try container.encode(self.firewallAllowAzureIps, forKey: .firewallAllowAzureIps)}
    if self.newTier != nil {try container.encode(self.newTier, forKey: .newTier)}
    if self.currentTier != nil {try container.encode(self.currentTier, forKey: .currentTier)}
    if self.maxJobCount != nil {try container.encode(self.maxJobCount, forKey: .maxJobCount)}
    if self.systemMaxJobCount != nil {try container.encode(self.systemMaxJobCount, forKey: .systemMaxJobCount)}
    if self.maxDegreeOfParallelism != nil {try container.encode(self.maxDegreeOfParallelism, forKey: .maxDegreeOfParallelism)}
    if self.systemMaxDegreeOfParallelism != nil {try container.encode(self.systemMaxDegreeOfParallelism, forKey: .systemMaxDegreeOfParallelism)}
    if self.maxDegreeOfParallelismPerJob != nil {try container.encode(self.maxDegreeOfParallelismPerJob, forKey: .maxDegreeOfParallelismPerJob)}
    if self.minPriorityPerJob != nil {try container.encode(self.minPriorityPerJob, forKey: .minPriorityPerJob)}
    if self.queryStoreRetention != nil {try container.encode(self.queryStoreRetention, forKey: .queryStoreRetention)}
  }
}

extension DataFactory {
  public static func createDataLakeAnalyticsAccountPropertiesProtocol() -> DataLakeAnalyticsAccountPropertiesProtocol {
    return DataLakeAnalyticsAccountPropertiesData()
  }
}
