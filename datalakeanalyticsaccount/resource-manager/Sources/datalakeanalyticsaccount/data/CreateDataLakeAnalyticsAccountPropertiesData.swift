// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
import Foundation
import azureSwiftRuntime
internal struct CreateDataLakeAnalyticsAccountPropertiesData : CreateDataLakeAnalyticsAccountPropertiesProtocol {
    public var defaultDataLakeStoreAccount: String
    public var dataLakeStoreAccounts: [AddDataLakeStoreWithAccountParametersProtocol]
    public var storageAccounts: [AddStorageAccountWithAccountParametersProtocol?]?
    public var computePolicies: [CreateComputePolicyWithAccountParametersProtocol?]?
    public var firewallRules: [CreateFirewallRuleWithAccountParametersProtocol?]?
    public var firewallState: FirewallStateEnum?
    public var firewallAllowAzureIps: FirewallAllowAzureIpsStateEnum?
    public var newTier: TierTypeEnum?
    public var maxJobCount: Int32?
    public var maxDegreeOfParallelism: Int32?
    public var maxDegreeOfParallelismPerJob: Int32?
    public var minPriorityPerJob: Int32?
    public var queryStoreRetention: Int32?

        enum CodingKeys: String, CodingKey {case defaultDataLakeStoreAccount = "defaultDataLakeStoreAccount"
        case dataLakeStoreAccounts = "dataLakeStoreAccounts"
        case storageAccounts = "storageAccounts"
        case computePolicies = "computePolicies"
        case firewallRules = "firewallRules"
        case firewallState = "firewallState"
        case firewallAllowAzureIps = "firewallAllowAzureIps"
        case newTier = "newTier"
        case maxJobCount = "maxJobCount"
        case maxDegreeOfParallelism = "maxDegreeOfParallelism"
        case maxDegreeOfParallelismPerJob = "maxDegreeOfParallelismPerJob"
        case minPriorityPerJob = "minPriorityPerJob"
        case queryStoreRetention = "queryStoreRetention"
        }

  public init(defaultDataLakeStoreAccount: String, dataLakeStoreAccounts: [AddDataLakeStoreWithAccountParametersProtocol])  {
    self.defaultDataLakeStoreAccount = defaultDataLakeStoreAccount
    self.dataLakeStoreAccounts = dataLakeStoreAccounts
  }

  public init(from decoder: Decoder) throws {
    let container = try decoder.container(keyedBy: CodingKeys.self)
      self.defaultDataLakeStoreAccount = try container.decode(String.self, forKey: .defaultDataLakeStoreAccount)
    self.dataLakeStoreAccounts = try container.decode([AddDataLakeStoreWithAccountParametersData].self, forKey: .dataLakeStoreAccounts)
    if container.contains(.storageAccounts) {
        self.storageAccounts = try container.decode([AddStorageAccountWithAccountParametersData?]?.self, forKey: .storageAccounts)
    }
    if container.contains(.computePolicies) {
        self.computePolicies = try container.decode([CreateComputePolicyWithAccountParametersData?]?.self, forKey: .computePolicies)
    }
    if container.contains(.firewallRules) {
        self.firewallRules = try container.decode([CreateFirewallRuleWithAccountParametersData?]?.self, forKey: .firewallRules)
    }
    if container.contains(.firewallState) {
        self.firewallState = try container.decode(FirewallStateEnum?.self, forKey: .firewallState)
    }
    if container.contains(.firewallAllowAzureIps) {
        self.firewallAllowAzureIps = try container.decode(FirewallAllowAzureIpsStateEnum?.self, forKey: .firewallAllowAzureIps)
    }
    if container.contains(.newTier) {
        self.newTier = try container.decode(TierTypeEnum?.self, forKey: .newTier)
    }
    if container.contains(.maxJobCount) {
        self.maxJobCount = try container.decode(Int32?.self, forKey: .maxJobCount)
    }
    if container.contains(.maxDegreeOfParallelism) {
        self.maxDegreeOfParallelism = try container.decode(Int32?.self, forKey: .maxDegreeOfParallelism)
    }
    if container.contains(.maxDegreeOfParallelismPerJob) {
        self.maxDegreeOfParallelismPerJob = try container.decode(Int32?.self, forKey: .maxDegreeOfParallelismPerJob)
    }
    if container.contains(.minPriorityPerJob) {
        self.minPriorityPerJob = try container.decode(Int32?.self, forKey: .minPriorityPerJob)
    }
    if container.contains(.queryStoreRetention) {
        self.queryStoreRetention = try container.decode(Int32?.self, forKey: .queryStoreRetention)
    }
    if var pageDecoder = decoder as? PageDecoder  {
      if pageDecoder.isPagedData,
        let nextLinkName = pageDecoder.nextLinkName {
          pageDecoder.nextLink = try UnknownCodingKey.decodeStringForKey(decoder: decoder, keyForDecode: nextLinkName)
      }
    }
  }

  public func encode(to encoder: Encoder) throws {
    var container = encoder.container(keyedBy: CodingKeys.self)
    try container.encode(self.defaultDataLakeStoreAccount, forKey: .defaultDataLakeStoreAccount)
    try container.encode(self.dataLakeStoreAccounts as! [AddDataLakeStoreWithAccountParametersData], forKey: .dataLakeStoreAccounts)
    if self.storageAccounts != nil {try container.encode(self.storageAccounts as! [AddStorageAccountWithAccountParametersData?]?, forKey: .storageAccounts)}
    if self.computePolicies != nil {try container.encode(self.computePolicies as! [CreateComputePolicyWithAccountParametersData?]?, forKey: .computePolicies)}
    if self.firewallRules != nil {try container.encode(self.firewallRules as! [CreateFirewallRuleWithAccountParametersData?]?, forKey: .firewallRules)}
    if self.firewallState != nil {try container.encode(self.firewallState, forKey: .firewallState)}
    if self.firewallAllowAzureIps != nil {try container.encode(self.firewallAllowAzureIps, forKey: .firewallAllowAzureIps)}
    if self.newTier != nil {try container.encode(self.newTier, forKey: .newTier)}
    if self.maxJobCount != nil {try container.encode(self.maxJobCount, forKey: .maxJobCount)}
    if self.maxDegreeOfParallelism != nil {try container.encode(self.maxDegreeOfParallelism, forKey: .maxDegreeOfParallelism)}
    if self.maxDegreeOfParallelismPerJob != nil {try container.encode(self.maxDegreeOfParallelismPerJob, forKey: .maxDegreeOfParallelismPerJob)}
    if self.minPriorityPerJob != nil {try container.encode(self.minPriorityPerJob, forKey: .minPriorityPerJob)}
    if self.queryStoreRetention != nil {try container.encode(self.queryStoreRetention, forKey: .queryStoreRetention)}
  }
}

extension DataFactory {
  public static func createCreateDataLakeAnalyticsAccountPropertiesProtocol(defaultDataLakeStoreAccount: String, dataLakeStoreAccounts: [AddDataLakeStoreWithAccountParametersProtocol]) -> CreateDataLakeAnalyticsAccountPropertiesProtocol {
    return CreateDataLakeAnalyticsAccountPropertiesData(defaultDataLakeStoreAccount: defaultDataLakeStoreAccount, dataLakeStoreAccounts: dataLakeStoreAccounts)
  }
}
